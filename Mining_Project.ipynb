{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e87708d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e87708d",
        "outputId": "185882c4-a217-425f-cd51-3d1b69c041b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd9ce6f4",
      "metadata": {
        "id": "bd9ce6f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "5c9bf387-2960-43b1-e31c-b9e53623b8be"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-faadacf631e6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tmdb_5000_credits.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tmdb_5000_movies.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1776\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: EOF inside string starting at row 3237"
          ]
        }
      ],
      "source": [
        "df1 = pd.read_csv('tmdb_5000_credits.csv')\n",
        "df2 = pd.read_csv('tmdb_5000_movies.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fd45d4f",
      "metadata": {
        "id": "0fd45d4f"
      },
      "source": [
        "### DATA CLEANING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52b0db70",
      "metadata": {
        "id": "52b0db70"
      },
      "outputs": [],
      "source": [
        "# observe Dataset_1\n",
        "df1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1699ad1",
      "metadata": {
        "id": "b1699ad1"
      },
      "outputs": [],
      "source": [
        "# observe Dataset_2\n",
        "df2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96c3a8ea",
      "metadata": {
        "id": "96c3a8ea"
      },
      "outputs": [],
      "source": [
        "# describe NaN and empty cells in each column\n",
        "for col in df1.columns:\n",
        "    nan_count = df1[col].isna().sum()\n",
        "    empty_count = df1[col].eq('').sum()\n",
        "    print(f\"Column {col}: NaN count = {nan_count}, Empty count = {empty_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16356e80",
      "metadata": {
        "id": "16356e80"
      },
      "outputs": [],
      "source": [
        "# Convert strings to lists of dictionaries\n",
        "df1[\"cast\"] = df1[\"cast\"].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
        "\n",
        "# Create new column in df1 - 'cast_names'\n",
        "df1[\"cast_names\"] = df1[\"cast\"].apply(lambda x: [d[\"name\"] for d in x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b993c8d4",
      "metadata": {
        "id": "b993c8d4"
      },
      "outputs": [],
      "source": [
        "crew_list = json.loads(df1['crew'][1])\n",
        "for crew_member in crew_list:\n",
        "    print(crew_member['job'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "769eba4c",
      "metadata": {
        "id": "769eba4c"
      },
      "outputs": [],
      "source": [
        "# extracting the top 3 fields\n",
        "#Director: The director has a significant impact on the overall vision and style of a movie, including the tone, pacing, camera work, and performance direction. Movies directed by the same director may have similar themes, visual styles, or narrative techniques, which can be used for recommendation purposes.\n",
        "\n",
        "#Screenplay writer: The screenplay is the foundation of a movie, providing the story, characters, dialogue, and structure. Similarities between movies based on the same source material or with similar themes, genres, or narrative structures can be identified and used for recommendation.\n",
        "\n",
        "#Producer: The producer oversees the financial and logistical aspects of a movie, including casting, hiring, scheduling, and marketing. The production company or studio associated with a movie may have a specific brand or target audience, which can be used for recommendation purposes. Additionally, producers may have a track record of successful movies or collaborations with specific directors or actors, which can also be used as a recommendation feature.\n",
        "\n",
        "# Apply literal_eval to convert stringified dictionaries to dictionaries\n",
        "df1[\"crew\"] = df1[\"crew\"].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
        "\n",
        "# Extract names of director, producer, and screenplay writer from crew list\n",
        "df1[\"director\"] = df1[\"crew\"].apply(lambda x: [d[\"name\"] for d in x if d[\"job\"] == \"Director\"][0] if [d[\"job\"] for d in x if d[\"job\"] == \"Director\"] else None)\n",
        "df1[\"producer\"] = df1[\"crew\"].apply(lambda x: [d[\"name\"] for d in x if d[\"job\"] == \"Producer\"])\n",
        "df1[\"screenplay_writer\"] = df1[\"crew\"].apply(lambda x: [d[\"name\"] for d in x if d[\"job\"] == \"Screenplay\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a42f582",
      "metadata": {
        "id": "3a42f582"
      },
      "outputs": [],
      "source": [
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84a5415f",
      "metadata": {
        "id": "84a5415f"
      },
      "outputs": [],
      "source": [
        "# describe NaN and empty cells in each df2 column\n",
        "for col in df2.columns:\n",
        "    nan_count = df2[col].isna().sum()\n",
        "    empty_count = df2[col].eq('').sum()\n",
        "    print(f\"Column {col}: NaN count = {nan_count}, Empty count = {empty_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54b87672",
      "metadata": {
        "id": "54b87672"
      },
      "outputs": [],
      "source": [
        "# convert the 'genres' column to dtype object\n",
        "df2['genres'] = df2['genres'].astype(object)\n",
        "\n",
        "# specify the key to extract\n",
        "key = 'name'\n",
        "\n",
        "# create a new column called 'genre_list'\n",
        "df2['genre_list'] = ''\n",
        "\n",
        "# loop through the values in the 'genres' column and extract the values for the specified key\n",
        "for i, genre_list in enumerate(df2['genres']):\n",
        "    genre_values = []\n",
        "    # check if the value is a string and convert it to a list of dictionaries if necessary\n",
        "    if isinstance(genre_list, str):\n",
        "        genre_list = ast.literal_eval(genre_list)\n",
        "    for genre_dict in genre_list:\n",
        "        if genre_dict.get(key):\n",
        "            genre_values.append(genre_dict[key])\n",
        "    df2.at[i, 'genre_list'] = genre_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c08047fc",
      "metadata": {
        "id": "c08047fc"
      },
      "outputs": [],
      "source": [
        "#Unpacking Keywords Column\n",
        "\n",
        "# convert the 'keywords' column to dtype object\n",
        "df2['keywords'] = df2['keywords'].astype(object)\n",
        "\n",
        "# specify the key to extract\n",
        "key = 'name'\n",
        "\n",
        "# create a new column called 'keywords_unpacked'\n",
        "df2['keywords_unpacked'] = ''\n",
        "\n",
        "# loop through the values in the 'keywords' column and extract the values for the specified key\n",
        "for i, keywords_unpacked in enumerate(df2['keywords']):\n",
        "    values = []\n",
        "    # check if the value is a string and convert it to a list of dictionaries if necessary\n",
        "    if isinstance(keywords_unpacked, str):\n",
        "        keywords_unpacked = ast.literal_eval(keywords_unpacked)\n",
        "    for key_dict in keywords_unpacked:\n",
        "        if key_dict.get(key):\n",
        "            values.append(key_dict[key])\n",
        "    df2.at[i, 'keywords_unpacked'] = values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0dd9dcc",
      "metadata": {
        "id": "e0dd9dcc"
      },
      "outputs": [],
      "source": [
        "# Movies with no overview\n",
        "nan_titles = []\n",
        "for idx, row in df2.iterrows():\n",
        "    if pd.isna(row['overview']):\n",
        "        nan_titles.append(row['original_title'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39bdefc9",
      "metadata": {
        "id": "39bdefc9"
      },
      "outputs": [],
      "source": [
        "# Create an empty list to store the data for the new dataframe\n",
        "data = []\n",
        "\n",
        "# Loop through the rows of the dataframe\n",
        "for index, row in df2.iterrows():\n",
        "    # check if the overview value is NaN\n",
        "    if pd.isna(row['overview']):\n",
        "        # if it is NaN, add the corresponding values to the data list\n",
        "        data.append({\n",
        "            'original_title': row['original_title'],\n",
        "            'homepage': row['homepage']\n",
        "        })\n",
        "\n",
        "# create the new dataframe from the data list\n",
        "df_sub = pd.DataFrame(data)\n",
        "df_sub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae6a69de",
      "metadata": {
        "id": "ae6a69de"
      },
      "outputs": [],
      "source": [
        "# Creating a dictionary with movie descriptions for blank movies, manually filled out.\n",
        "dict1 = {\n",
        "'The Dark Knight': 'A superhero action-thriller where Batman battles the Joker to save Gotham City. The movie showcases intense fight scenes and explores the dark psychological struggles of the characters.',\n",
        "'Inside Out': 'An animated adventure movie that explores the emotions and memories of a young girl. The film provides a creative portrayal of complex emotions and has a heartwarming message about growing up.',\n",
        "'Guardians of the Galaxy': 'A superhero space opera where a group of misfits team up to save the galaxy from a powerful villain. The movie features an eclectic soundtrack and a mix of action, humor, and heart.',\n",
        "'Interstellar': 'A science fiction movie where a group of astronauts travel through a wormhole in search of a new home for humanity. The film combines stunning visuals with complex theories of space and time.',\n",
        "'Inception': 'A mind-bending heist movie where a thief steals information by entering people’s dreams. The movie is known for its intricate plot and stunning visual effects that keep the audience on the edge of their seats.',\n",
        "'The Lord of the Rings: The Fellowship of the Ring': 'An epic fantasy movie where a young hobbit must destroy a powerful ring to save Middle-earth from evil. The movie features breathtaking landscapes, epic battles, and memorable characters.',\n",
        "'Django Unchained': 'A western drama where a freed slave teams up with a bounty hunter to rescue his wife from a brutal plantation owner. The film is known for its gritty realism and powerful performances.',\n",
        "'The Wolf of Wall Street': 'A biographical black comedy movie that follows the rise and fall of a corrupt stockbroker. The movie showcases the excess and corruption of Wall Street in the 1990s and features a dynamic performance from Leonardo DiCaprio.',\n",
        "'The Lord of the Rings: The Return of the King': 'The final installment of the epic fantasy trilogy where the fate of Middle-earth is decided in a climactic battle. The movie provides a satisfying conclusion to the story with stunning action sequences and emotional moments.',\n",
        "'The Lord of the Rings: The Two Towers': 'The second installment of the epic fantasy trilogy where the fellowship is scattered and faces new challenges. The movie features epic battles and a deeper exploration of the characters and their motivations.',\n",
        "'The Lion King': 'An animated musical movie where a young lion prince must reclaim his throne from his treacherous uncle. The movie features memorable songs and breathtaking animation that brings the African savannah to life.',\n",
        "'The Matrix': 'A science fiction action movie where a hacker discovers the truth about reality and leads a rebellion against intelligent machines. The movie features groundbreaking special effects and a thought-provoking exploration of reality and identity.',\n",
        "'Fight Club': 'A psychological drama movie where an insomniac office worker forms a secret club that evolves into a violent anarchist movement. The movie features an unreliable narrator and a subversive critique of consumer culture.',\n",
        "'The Green Mile': 'A supernatural drama movie where a prison guard discovers that an inmate on death row has miraculous healing powers. The movie explores themes of justice, morality, and redemption with powerful performances from the cast.',\n",
        "'Forrest Gump': 'A comedy-drama movie that follows the life of a simple man who unwittingly becomes part of some of the defining moments of the 20th century. The movie features a heartwarming message about the power of kindness and perseverance.',\n",
        "'Se7en': 'A crime thriller movie where two detectives track down a serial killer who uses the seven deadly sins as his inspiration. The movie is known for its gritty atmosphere and suspenseful storytelling.',\n",
        " \"Schindler's List\": 'A poignant historical drama that depicts the heroic acts of a German businessman who risks everything to save the lives of Jewish refugees during the Holocaust.',\n",
        "\"The Shawshank Redemption\": 'A gripping prison drama that portrays the unbreakable bond between two inmates, as they navigate the harsh realities of life behind bars.',\n",
        "\"The Empire Strikes Back\": 'A thrilling space epic that continues the Star Wars saga, as the rebels face new challenges and the Force is further explored.',\n",
        "\"The Silence of the Lambs\": 'A chilling psychological thriller that delves into the mind of a cannibalistic serial killer, as an FBI agent races against time to catch another killer on the loose.',\n",
        "\"Back to the Future\": 'A time-traveling adventure-comedy that is full of action, humor, and heart, as a teenager tries to fix the past and secure his future.',\n",
        "\"千と千尋の神隠し\": 'A captivating and visually stunning animated film that takes the audience on a magical journey through a mystical world filled with strange creatures and enigmatic spirits.',\n",
        "\"The Imitation Game\": 'A gripping historical drama that pays tribute to a brilliant mathematician and codebreaker who played a pivotal role in saving countless lives during World War II.',\n",
        "\"Chiamatemi Francesco - Il Papa della gente\": 'An inspiring biographical film that tells the story of a man who dedicated his life to serving others and became a beacon of hope and compassion for millions around the world.',\n",
        "\"The Godfather: Part II\": 'A complex and riveting crime drama that explores the rise of a powerful mafia family and the struggles of its heirs to maintain control and protect their loved ones.',\n",
        "\"Star Wars\": 'An iconic and imaginative sci-fi adventure that takes the audience on a thrilling ride through a galaxy far, far away, as a group of rebels fight to overthrow an oppressive regime.',\n",
        "\"Pulp Fiction\": 'A groundbreaking crime film that blends humor, violence, and pop culture in a way that defies expectations and challenges conventions.',\n",
        "\"The Godfather\": 'A masterful crime drama that explores the dark side of power and loyalty, as a patriarch of a powerful mafia family struggles to maintain his authority and protect his loved ones.',\n",
        "\"Whiplash\": 'A powerful and intense drama that delves into the obsessive world of music, as a young drummer is pushed to his limits by a demanding and abusive instructor.',\n",
        "\"To Be Frank, Sinatra at 100\": 'A fascinating documentary that celebrates the life and legacy of one of the greatest entertainers of all time, as friends, family, and fellow musicians reflect on his impact and influence.',\n",
        "\"Food Chains\": 'A thought-provoking documentary that sheds light on the harsh realities of farm labor in America, as workers fight for their rights and fair treatment in a system that often exploits them.'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afdc1f02",
      "metadata": {
        "id": "afdc1f02"
      },
      "outputs": [],
      "source": [
        "#Filling in empty overview values using corresponding values from dict1 into df2:\n",
        "\n",
        "# Iterate over keys in dict1\n",
        "for key in dict1:\n",
        "    # Check if key matches any value in \"title\" column of df2\n",
        "    mask = df2['title'] == key\n",
        "    if mask.any():\n",
        "        # Update \"overview\" column with value from dict1\n",
        "        df2.loc[mask, 'overview'] = dict1[key]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9480143f",
      "metadata": {
        "id": "9480143f"
      },
      "outputs": [],
      "source": [
        "# Drop one of the 'title' columns based on the duplicate mask\n",
        "df2 = df2.drop('title', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0dc6e5f",
      "metadata": {
        "id": "a0dc6e5f"
      },
      "outputs": [],
      "source": [
        "# Combining the dataframes by concatenating them horizontally\n",
        "df = pd.concat([df1, df2], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68562bdb",
      "metadata": {
        "id": "68562bdb"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b30d6776",
      "metadata": {
        "id": "b30d6776"
      },
      "outputs": [],
      "source": [
        "# Get a list of all columns in the dataframe\n",
        "columns = df.columns.tolist()\n",
        "columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbf83f41",
      "metadata": {
        "id": "dbf83f41"
      },
      "outputs": [],
      "source": [
        "# Droping unnecessary columns from the dataframe\n",
        "df = df.drop(['movie_id', 'cast', 'crew', 'genres','popularity','tagline','runtime','release_date','production_companies','production_countries','homepage', 'id', 'keywords','original_language','original_title','revenue','spoken_languages','status'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86460ae8",
      "metadata": {
        "id": "86460ae8"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8cca6d5",
      "metadata": {
        "id": "f8cca6d5"
      },
      "outputs": [],
      "source": [
        "# Get the number of NaN and empty cells in each column\n",
        "nan_counts = df.isna().sum()\n",
        "empty_counts = (df.fillna('') == '').sum()\n",
        "\n",
        "# Print the results\n",
        "print(\"NaN counts:\\n\", nan_counts)\n",
        "print(\"\\nEmpty counts:\\n\", empty_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaf64fe6",
      "metadata": {
        "id": "aaf64fe6"
      },
      "outputs": [],
      "source": [
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73d12e78",
      "metadata": {
        "id": "73d12e78"
      },
      "outputs": [],
      "source": [
        "# define a function to convert list values to string\n",
        "def list_to_string(val):\n",
        "    if isinstance(val, list):\n",
        "        return ', '.join(val)\n",
        "    return str(val)\n",
        "\n",
        "# apply the function to the specified columns and create the \"text\" column\n",
        "df['text'] = df.apply(lambda row: ' '.join([\n",
        "    list_to_string(row['director']),\n",
        "    list_to_string(row['title']),\n",
        "    list_to_string(row['cast_names']),\n",
        "    list_to_string(row['overview']),\n",
        "    list_to_string(row['producer']),\n",
        "    list_to_string(row['screenplay_writer']),\n",
        "    list_to_string(row['genre_list']),\n",
        "    list_to_string(row['keywords_unpacked'])\n",
        "]), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3a87ac8",
      "metadata": {
        "id": "f3a87ac8"
      },
      "outputs": [],
      "source": [
        "df['text'][1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the weighted average of vote_average and vote_count\n",
        "voters = df['vote_count']\n",
        "avg_votes = df['vote_average']\n",
        "C = avg_votes.mean()\n",
        "m = voters.quantile(0.90)\n",
        "weighted_rating = (voters/(voters+m) * avg_votes) + (m/(m+voters) * C)\n",
        "\n",
        "# Add the weighted_rating column to the merged_df DataFrame\n",
        "df['weighted_rating'] = weighted_rating"
      ],
      "metadata": {
        "id": "_Lbyuug26HA-"
      },
      "id": "_Lbyuug26HA-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "91292102",
      "metadata": {
        "id": "91292102"
      },
      "source": [
        "### DATA PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d067f3d5",
      "metadata": {
        "id": "d067f3d5"
      },
      "outputs": [],
      "source": [
        "# Create function to clean text\n",
        "def clean_text(text):\n",
        "    if isinstance(text, str):\n",
        "        # Remove punctuation and non-alphanumeric characters using regex\n",
        "        text_clean = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "        # Remove extra whitespace\n",
        "        text_clean = re.sub(r'\\s+', ' ', text_clean).strip()\n",
        "    else:\n",
        "        text_clean = \"\"\n",
        "    return text_clean\n",
        "\n",
        "# Clean the overview column\n",
        "df['text_clean'] = df['text'].apply(lambda x: clean_text(x))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bdeb3ce",
      "metadata": {
        "id": "1bdeb3ce"
      },
      "outputs": [],
      "source": [
        "# Create function to tokenize and lowercase data\n",
        "def tokenize(text):\n",
        "    # W+ means that either a word character (A-Za-z0-9_) or a dash (-) can go there.\n",
        "    tokens = re.split('\\W+', text)\n",
        "    return tokens\n",
        "\n",
        "# Tokenize and lowercase data\n",
        "df['text_tokenized'] = df['text_clean'].apply(lambda x: tokenize(x.lower()))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb1d7793",
      "metadata": {
        "id": "fb1d7793"
      },
      "outputs": [],
      "source": [
        "# Define stop words list\n",
        "stopwords = nltk.corpus.stopwords.words('english')     # All English Stopwords\n",
        "stopwords\n",
        "\n",
        "# Create function to remove stopwords\n",
        "def remove_stopwords(tokenized_list):\n",
        "    text = [word for word in tokenized_list if word not in stopwords]\n",
        "    return text\n",
        "\n",
        "# Remove stop words from data\n",
        "df['text_nostop'] = df['text_tokenized'].apply(lambda x: remove_stopwords(x))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8928f137",
      "metadata": {
        "id": "8928f137"
      },
      "outputs": [],
      "source": [
        "wn = nltk.WordNetLemmatizer()\n",
        "\n",
        "# Create function to apply lematizer\n",
        "def lemmatizing(tokenized_text):\n",
        "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
        "    return text\n",
        "\n",
        "# Apply lemmatizer\n",
        "df['text_lemmatized'] = df['text_nostop'].apply(lambda x: lemmatizing(x))\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ba980f0",
      "metadata": {
        "id": "1ba980f0"
      },
      "outputs": [],
      "source": [
        "#Vectorization\n",
        "tfidf_vect = TfidfVectorizer(analyzer=lambda x: ' '.join([word for word in x]))\n",
        "tfidf_counts = tfidf_vect.fit_transform(df['text_lemmatized'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8994b1f",
      "metadata": {
        "id": "a8994b1f"
      },
      "outputs": [],
      "source": [
        "# Compute pairwise cosine similarity on tf-idf matrix\n",
        "cosine_sim = cosine_similarity(tfidf_counts, tfidf_counts)\n",
        "\n",
        "# Print similarity matrix\n",
        "print(cosine_sim)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef7fdba9",
      "metadata": {
        "id": "ef7fdba9"
      },
      "source": [
        "#Create a dataframe that contains only the title and overview_lemmatized columns from your original dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42337e7e",
      "metadata": {
        "id": "42337e7e"
      },
      "outputs": [],
      "source": [
        "df_movies = df[['title', 'text_lemmatized']]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "183083f4",
      "metadata": {
        "id": "183083f4"
      },
      "source": [
        "#Define a function that takes a movie title as input, and returns the top 5 most similar movies based on cosine similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b075246",
      "metadata": {
        "id": "9b075246"
      },
      "outputs": [],
      "source": [
        "def get_movie_recomendation(title):\n",
        "    # Get index of the input movie\n",
        "    index = df_movies[df_movies['title'] == title].index[0]\n",
        "\n",
        "    # Calculate cosine similarity between the input movie and all other movies\n",
        "    cosine_similarities = cosine_similarity(tfidf_counts[index], tfidf_counts)\n",
        "\n",
        "    # Get the top 5 most similar movies\n",
        "    similar_movies_indices = cosine_similarities.argsort()[0][-6:-1][::-1]\n",
        "    similar_movies = df_movies.iloc[similar_movies_indices]['title']\n",
        "\n",
        "    return similar_movies.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea1968eb",
      "metadata": {
        "id": "ea1968eb"
      },
      "outputs": [],
      "source": [
        "get_movie_recomendation ('The Dark Knight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7942da6f",
      "metadata": {
        "id": "7942da6f"
      },
      "outputs": [],
      "source": [
        "get_movie_recomendation ('The Shawshank Redemption')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d258ed1",
      "metadata": {
        "id": "3d258ed1"
      },
      "outputs": [],
      "source": [
        "get_movie_recomendation ('Frozen')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Trying a different method"
      ],
      "metadata": {
        "id": "gfr22Zn0O-nC"
      },
      "id": "gfr22Zn0O-nC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "credits = pd.read_csv('tmdb_5000_credits.csv')\n",
        "movies = pd.read_csv('tmdb_5000_movies.csv')"
      ],
      "metadata": {
        "id": "acRxAqWQDmHL"
      },
      "id": "acRxAqWQDmHL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa6ac04b",
      "metadata": {
        "id": "aa6ac04b"
      },
      "outputs": [],
      "source": [
        "credits.columns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract values from a dict\n",
        "def get_names(lst):\n",
        "    feat = []\n",
        "    for i in ast.literal_eval(lst):\n",
        "        feat.append(i['name'])          # All the needed keywords has the key 'name'\n",
        "    return feat"
      ],
      "metadata": {
        "id": "8SMvynVGDvSY"
      },
      "id": "8SMvynVGDvSY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract needed values\n",
        "\n",
        "movies['genres_names'] = movies['genres'].apply(get_names)\n",
        "\n",
        "movies['keywords_names'] = movies['keywords'].apply(get_names)\n",
        "\n",
        "movies['prod_companies_names'] = movies['production_companies'].apply(get_names)\n",
        "\n",
        "movies['prod_countries_names'] = movies['production_countries'].apply(get_names)\n",
        "\n",
        "movies['spoken_lang_names'] = movies['spoken_languages'].apply(get_names)"
      ],
      "metadata": {
        "id": "3cN4OCTyDyA4"
      },
      "id": "3cN4OCTyDyA4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "credits.head(2)"
      ],
      "metadata": {
        "id": "d0IZhMu3ECS8"
      },
      "id": "d0IZhMu3ECS8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "credits[\"cast\"] = credits[\"cast\"].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
        "\n",
        "credits[\"cast_names\"] = credits[\"cast\"].apply(lambda x: [d[\"name\"] for d in x])"
      ],
      "metadata": {
        "id": "RXbrT4rUELm4"
      },
      "id": "RXbrT4rUELm4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply literal_eval to convert stringified dictionaries to dictionaries\n",
        "credits[\"crew\"] = credits[\"crew\"].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
        "\n",
        "# Extract names of director, producer, and screenplay writer from crew list\n",
        "credits[\"director\"] = credits[\"crew\"].apply(lambda x: [d[\"name\"] for d in x if d[\"job\"] == \"Director\"][0] if [d[\"job\"] for d in x if d[\"job\"] == \"Director\"] else None)\n",
        "credits[\"producer\"] = credits[\"crew\"].apply(lambda x: [d[\"name\"] for d in x if d[\"job\"] == \"Producer\"])"
      ],
      "metadata": {
        "id": "I_t2KHe6Hk_q"
      },
      "id": "I_t2KHe6Hk_q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop the original columns from which names have been extracted\n",
        "\n",
        "credits1 = credits.drop(['cast','crew'], axis =1)\n",
        "movies1 = movies.drop(['genres', 'keywords', 'production_companies', 'production_countries', 'spoken_languages', 'homepage', 'original_title'], axis = 1)"
      ],
      "metadata": {
        "id": "dOdsEjcvEePV"
      },
      "id": "dOdsEjcvEePV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the two dataframes\n",
        "new_df = new_df = pd.merge(credits1, movies1, left_on='movie_id', right_on='id')\n",
        "\n",
        "# Drop the 'id' column from the movies1 dataframe\n",
        "new_df.drop('id', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "H9bR5D1zEhsB"
      },
      "id": "H9bR5D1zEhsB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to remove repetitive words\n",
        "def remove_repetitive_words(name):\n",
        "    # List of words to remove\n",
        "    words_to_remove = ['Pictures', 'Films', 'Entertainment', 'Productions', 'Studios', 'Company', 'Media', 'films', 'entertainment', 'film']\n",
        "\n",
        "    # Split the name into words\n",
        "    words = name.split()\n",
        "\n",
        "    # Remove the words_to_remove\n",
        "    words = [word for word in words if word not in words_to_remove]\n",
        "\n",
        "    # Join the words back together\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Apply the function to the column\n",
        "new_df['prod_companies_names'] = new_df['prod_companies_names'].apply(lambda x: [remove_repetitive_words(name) for name in x])"
      ],
      "metadata": {
        "id": "H3s3yDQtY-Zy"
      },
      "id": "H3s3yDQtY-Zy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the list of lists\n",
        "lang = [lan for lans in new_df['spoken_lang_names'] for lan in lans]\n",
        "\n",
        "# Get the unique values\n",
        "unique_lang = set(lang)\n",
        "\n",
        "# Print the unique values\n",
        "print(unique_lang)"
      ],
      "metadata": {
        "id": "va2KyqNYbFqQ"
      },
      "id": "va2KyqNYbFqQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove spaces from the cast_names, director, and producer columns\n",
        "new_df['cast_names'] = new_df['cast_names'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
        "new_df['director'] = new_df['director'].str.replace(\" \", \"\")\n",
        "new_df['producer'] = new_df['producer'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
        "new_df['prod_countries_names'] = new_df['prod_countries_names'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
        "new_df['prod_companies_names'] = new_df['prod_companies_names'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
        "new_df['spoken_lang_names'] = new_df['spoken_lang_names'].apply(lambda x: [i.replace(\" \", \"\") for i in x])"
      ],
      "metadata": {
        "id": "oqYjd6mBJVKK"
      },
      "id": "oqYjd6mBJVKK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.head(2)"
      ],
      "metadata": {
        "id": "iyFBY1TZpNed"
      },
      "id": "iyFBY1TZpNed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_# define a function to convert list values to string\n",
        "def list_to_string(val):\n",
        "    if isinstance(val, list):\n",
        "        return ', '.join(val)\n",
        "    return str(val)\n",
        "\n",
        "# apply the function to the specified columns and create the \"text\" column\n",
        "new_df['text'] = new_df.apply(lambda row: ' '.join([\n",
        "    list_to_string(row['director']),\n",
        "    list_to_string(row['title_x']),\n",
        "    list_to_string(row['cast_names']),\n",
        "    list_to_string(row['overview']),\n",
        "    list_to_string(row['producer']),\n",
        "    list_to_string(row['genres_names']),\n",
        "    list_to_string(row['keywords_names'])\n",
        "]), axis=1)"
      ],
      "metadata": {
        "id": "Mlnkm9Piooah"
      },
      "id": "Mlnkm9Piooah",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.head(2)"
      ],
      "metadata": {
        "id": "-H7zwPwv6W3v"
      },
      "id": "-H7zwPwv6W3v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove the redundant columns\n",
        "new_df = new_df.drop(['cast_names', 'director', 'producer','status', 'title_y', 'movie_id', 'prod_countries_names', 'prod_companies_names', 'spoken_lang_names'], axis=1)\n",
        "\n",
        "new_df.head(2)"
      ],
      "metadata": {
        "id": "aQ5EdPliouGZ"
      },
      "id": "aQ5EdPliouGZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# define lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# function to tokenize, remove stop words and lemmatize text\n",
        "def preprocess_text(text):\n",
        "    if text is not None and isinstance(text, str):\n",
        "        # tokenize the text into words\n",
        "        words = word_tokenize(text.lower())\n",
        "        # remove stop words from the words list\n",
        "        words = [word for word in words if word not in stopwords.words('english')]\n",
        "        # lemmatize the words\n",
        "        lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "        # join the lemmatized words to form a text string\n",
        "        lemmatized_text = ' '.join(lemmatized_words)\n",
        "        return lemmatized_text\n",
        "    else:\n",
        "        return \"\"\n",
        "\n",
        "# apply preprocessing function to the 'overview' column in the merged_df dataframe\n",
        "new_df['tagline'] = new_df['tagline'].apply(preprocess_text)\n",
        "new_df['overview'] = new_df['overview'].apply(preprocess_text)\n",
        "new_df['title_y'] = new_df['title_x'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "cm-LOa8OVUIg"
      },
      "id": "cm-LOa8OVUIg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unnecessary columns\n",
        "new_df.drop(['genres_names', 'keywords_names', 'overview', 'tagline', 'original_language', 'title_y'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "1aoghv2PdwfW"
      },
      "id": "1aoghv2PdwfW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.head(2)"
      ],
      "metadata": {
        "id": "FTCILLjTd3aK"
      },
      "id": "FTCILLjTd3aK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining columns vote_averge and vote_count\n",
        "new_df['rating'] = new_df['vote_average'] * new_df['vote_count']\n",
        "\n",
        "#categorizing them by creating bins\n",
        "bins = pd.qcut(new_df['rating'], q=4, labels=['bad', 'okay', 'good', 'great'])\n",
        "dummies = pd.get_dummies(bins, prefix='rating')\n",
        "\n",
        "# combine encoded vote category columns to original df\n",
        "new_df = pd.concat([new_df, dummies], axis=1)\n",
        "\n",
        "# drop original vote_count and vote_average columns\n",
        "new_df = new_df.drop(['vote_count', 'vote_average'], axis=1)"
      ],
      "metadata": {
        "id": "bV-SYuXg-DrM"
      },
      "id": "bV-SYuXg-DrM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#categorizing runtime\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(new_df['runtime'], bins=10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L7gpC09oBeuk"
      },
      "id": "L7gpC09oBeuk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create a function to categorize the runtime\n",
        "def categorize_runtime(runtime):\n",
        "    if runtime < 90:\n",
        "        return 'Short'\n",
        "    elif runtime <= 150:\n",
        "        return 'Medium'\n",
        "    else:\n",
        "        return 'Long'\n",
        "\n",
        "# Apply the categorize_runtime function to create a new column\n",
        "new_df['runtime_cat'] = np.vectorize(categorize_runtime)(new_df['runtime'])"
      ],
      "metadata": {
        "id": "rsi9NoLABjU3"
      },
      "id": "rsi9NoLABjU3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df['popularity'].describe()"
      ],
      "metadata": {
        "id": "H8NtEnqHB8O-"
      },
      "id": "H8NtEnqHB8O-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df['budget'].describe()"
      ],
      "metadata": {
        "id": "VbNJ2ugRF8uT"
      },
      "id": "VbNJ2ugRF8uT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# categorize 'popularity' into 3 bins using pandas qcut function\n",
        "new_df['popularity_bins'] = pd.qcut(new_df['popularity'], q=3, labels=['low', 'medium', 'high'])"
      ],
      "metadata": {
        "id": "5KtKGaMwDTET"
      },
      "id": "5KtKGaMwDTET",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the bin edges\n",
        "bin_edges = [0, 50000000, 150000000, float('inf')]\n",
        "\n",
        "# Define the bin labels\n",
        "bin_labels = ['Low', 'Medium', 'High']\n",
        "\n",
        "# Create a new column with the budget category\n",
        "new_df['budget_bins'] = pd.cut(new_df['budget'], bins=bin_edges, labels=bin_labels)\n",
        "\n",
        "# Drop the original 'budget' column\n",
        "new_df = new_df.drop(['budget', 'popularity','runtime'], axis=1)"
      ],
      "metadata": {
        "id": "nxv-cn3DBrJL"
      },
      "id": "nxv-cn3DBrJL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dummy variables for popularity_bins and budget_bins\n",
        "popularity_dummies = pd.get_dummies(new_df['popularity_bins'], prefix='popularity')\n",
        "budget_dummies = pd.get_dummies(new_df['budget_bins'], prefix='budget')\n",
        "\n",
        "# concatenate the dummy variables with the original dataframe\n",
        "new_df = pd.concat([new_df, popularity_dummies, budget_dummies], axis=1)\n",
        "\n",
        "# drop the original categorical columns\n",
        "#new_df.drop(['popularity_bins', 'budget_bins'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "qI5Bgvx8DpZ_"
      },
      "id": "qI5Bgvx8DpZ_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert release_date to datetime format\n",
        "new_df['release_date'] = pd.to_datetime(new_df['release_date'])\n",
        "\n",
        "# Categorize release_date into 3 categories\n",
        "new_df['release_date_cat'] = pd.cut(new_df['release_date'], bins=3, labels=['early', 'mid', 'late'])\n",
        "\n",
        "# Encode release_date_cat column\n",
        "release_date_cat_encoded = pd.get_dummies(new_df['release_date_cat'], prefix='release_date_cat')\n",
        "\n",
        "# Concatenate with original DataFrame\n",
        "new_df = pd.concat([new_df, release_date_cat_encoded], axis=1)\n",
        "\n",
        "# Drop original release_date and release_date_cat columns\n",
        "#new_df = new_df.drop(['release_date', 'release_date_cat'], axis=1)"
      ],
      "metadata": {
        "id": "EItXcKphHHfs"
      },
      "id": "EItXcKphHHfs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 25th and 75th percentile values of revenue\n",
        "q1 = new_df['revenue'].quantile(0.25)\n",
        "q3 = new_df['revenue'].quantile(0.75)"
      ],
      "metadata": {
        "id": "WxSHmzNSHPco"
      },
      "id": "WxSHmzNSHPco",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorize revenue into 3 bins\n",
        "new_df['revenue_cat'] = pd.cut(new_df['revenue'], bins=[-np.inf, q1, q3, np.inf], labels=['Low', 'Medium', 'High'])\n",
        "\n",
        "# Encode revenue categories using dummy encoding\n",
        "new_df = pd.concat([new_df, pd.get_dummies(new_df['revenue_cat'], prefix='revenue')], axis=1)\n",
        "\n",
        "# Drop the original 'revenue' and 'revenue_cat' columns\n",
        "#new_df.drop(['revenue', 'revenue_cat'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "jp-Pu0lRHTin"
      },
      "id": "jp-Pu0lRHTin",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.head(2)"
      ],
      "metadata": {
        "id": "sIfphQJfCxcb"
      },
      "id": "sIfphQJfCxcb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EVOKtyC0G1Tg"
      },
      "id": "EVOKtyC0G1Tg"
    },
    {
      "cell_type": "code",
      "source": [
        "wn = nltk.WordNetLemmatizer()\n",
        "\n",
        "# Create function to apply lematizer\n",
        "def lemmatizing(tokenized_text):\n",
        "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
        "    return text\n",
        "\n",
        "# Apply lemmatizer\n",
        "new_df['text'] = new_df['text'].apply(lambda x: lemmatizing(x))"
      ],
      "metadata": {
        "id": "_j5E8uw4eGGq"
      },
      "id": "_j5E8uw4eGGq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Vectorization\n",
        "tfidf_vect = TfidfVectorizer(analyzer=lambda x: ' '.join([word for word in x]))\n",
        "tfidf_counts = tfidf_vect.fit_transform(new_df['text'])"
      ],
      "metadata": {
        "id": "ieyK6Vgdkc8l"
      },
      "id": "ieyK6Vgdkc8l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute pairwise cosine similarity on tf-idf matrix\n",
        "cosine_sim = cosine_similarity(tfidf_counts, tfidf_counts)\n",
        "\n",
        "# Print similarity matrix\n",
        "print(cosine_sim)"
      ],
      "metadata": {
        "id": "kTnnWvf8kjXT"
      },
      "id": "kTnnWvf8kjXT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a dataframe that contains only the title and overview_lemmatized columns from your original dataframe\n",
        "df_movies = new_df[['title_x', 'text']]\n",
        "df_movies['title'] = df_movies['title_x']"
      ],
      "metadata": {
        "id": "BXaf-OOmknyW"
      },
      "id": "BXaf-OOmknyW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_movie_recomendation(title):\n",
        "    # Get index of the input movie\n",
        "    index = df_movies[df_movies['title'] == title].index[0]\n",
        "\n",
        "    # Calculate cosine similarity between the input movie and all other movies\n",
        "    cosine_similarities = cosine_similarity(tfidf_counts[index], tfidf_counts)\n",
        "\n",
        "    # Get the top 5 most similar movies\n",
        "    similar_movies_indices = cosine_similarities.argsort()[0][-6:-1][::-1]\n",
        "    similar_movies = df_movies.iloc[similar_movies_indices]['title']\n",
        "\n",
        "    return similar_movies.tolist()"
      ],
      "metadata": {
        "id": "TnwIadMtmnyN"
      },
      "id": "TnwIadMtmnyN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df_knn = new_df[['budget_bins', 'popularity_bins', 'revenue_cat', 'release_date_cat', 'text']]\n",
        "print(new_df_knn)"
      ],
      "metadata": {
        "id": "VnDZbr9zIgf6"
      },
      "id": "VnDZbr9zIgf6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_movie_recomendation ('The Dark Knight')"
      ],
      "metadata": {
        "id": "WMoAQt4DmrGX"
      },
      "id": "WMoAQt4DmrGX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_movie_recomendation ('The Shawshank Redemption')"
      ],
      "metadata": {
        "id": "jMS7bNSpm-QY"
      },
      "id": "jMS7bNSpm-QY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_movie_recomendation ('Frozen')"
      ],
      "metadata": {
        "id": "7x-Alp00nBPR"
      },
      "id": "7x-Alp00nBPR",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}